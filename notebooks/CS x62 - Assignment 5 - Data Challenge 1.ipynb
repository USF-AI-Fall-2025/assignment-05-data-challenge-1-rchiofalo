{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b168483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTRICT_TYPE</th>\n",
       "      <th>DISTRICT_NAME</th>\n",
       "      <th>DISTRICT_CODE</th>\n",
       "      <th>ACADEMIC_YEAR</th>\n",
       "      <th>DEMO_CATEGORY</th>\n",
       "      <th>STUDENT_POPULATION</th>\n",
       "      <th>AWARD_CATEGORY</th>\n",
       "      <th>WAGE_YEAR1</th>\n",
       "      <th>WAGE_YEAR2</th>\n",
       "      <th>WAGE_YEAR3</th>\n",
       "      <th>WAGE_YEAR4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>School District</td>\n",
       "      <td>Duarte Unified</td>\n",
       "      <td>1964469.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>None Reported</td>\n",
       "      <td>Bachelor's Degree - Did Not Transfer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>School District</td>\n",
       "      <td>Coronado Unified</td>\n",
       "      <td>3768031.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>None Reported</td>\n",
       "      <td>Associate Degree</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>School District</td>\n",
       "      <td>Gilroy Unified</td>\n",
       "      <td>4369484.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Bachelor's Degree - Did Not Transfer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School District</td>\n",
       "      <td>Pleasant Valley</td>\n",
       "      <td>5672553.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Homeless Status</td>\n",
       "      <td>Did Not Experience Homelessness in K-12</td>\n",
       "      <td>Community College Certificate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legislative District</td>\n",
       "      <td>Senate District 15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Community College Certificate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20700</th>\n",
       "      <td>School District</td>\n",
       "      <td>Armona Union Elementary</td>\n",
       "      <td>1663875.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Associate Degree</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20701</th>\n",
       "      <td>School District</td>\n",
       "      <td>Taft Union High</td>\n",
       "      <td>1563818.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Race</td>\n",
       "      <td>White</td>\n",
       "      <td>Community College Certificate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20702</th>\n",
       "      <td>School District</td>\n",
       "      <td>Bassett Unified</td>\n",
       "      <td>1964295.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Foster Status</td>\n",
       "      <td>Foster Youth</td>\n",
       "      <td>Bachelor's Degree - Did Not Transfer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20703</th>\n",
       "      <td>School District</td>\n",
       "      <td>SBE - John Henry High</td>\n",
       "      <td>777354.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's Degree - Did Not Transfer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20704</th>\n",
       "      <td>School District</td>\n",
       "      <td>Los Molinos Unified</td>\n",
       "      <td>5271571.0</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Foster Status</td>\n",
       "      <td>Not Foster Youth</td>\n",
       "      <td>Associate Degree</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20705 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DISTRICT_TYPE            DISTRICT_NAME  DISTRICT_CODE  \\\n",
       "0           School District           Duarte Unified      1964469.0   \n",
       "1           School District         Coronado Unified      3768031.0   \n",
       "2           School District           Gilroy Unified      4369484.0   \n",
       "3           School District          Pleasant Valley      5672553.0   \n",
       "4      Legislative District       Senate District 15            NaN   \n",
       "...                     ...                      ...            ...   \n",
       "20700       School District  Armona Union Elementary      1663875.0   \n",
       "20701       School District          Taft Union High      1563818.0   \n",
       "20702       School District          Bassett Unified      1964295.0   \n",
       "20703       School District    SBE - John Henry High       777354.0   \n",
       "20704       School District      Los Molinos Unified      5271571.0   \n",
       "\n",
       "      ACADEMIC_YEAR    DEMO_CATEGORY                       STUDENT_POPULATION  \\\n",
       "0         2018-2019             Race                            None Reported   \n",
       "1         2018-2019             Race                            None Reported   \n",
       "2         2018-2019             Race                Black or African American   \n",
       "3         2018-2019  Homeless Status  Did Not Experience Homelessness in K-12   \n",
       "4         2018-2019             Race         American Indian or Alaska Native   \n",
       "...             ...              ...                                      ...   \n",
       "20700     2018-2019             Race         American Indian or Alaska Native   \n",
       "20701     2018-2019             Race                                    White   \n",
       "20702     2018-2019    Foster Status                             Foster Youth   \n",
       "20703     2018-2019           Gender                                     Male   \n",
       "20704     2018-2019    Foster Status                         Not Foster Youth   \n",
       "\n",
       "                             AWARD_CATEGORY  WAGE_YEAR1  WAGE_YEAR2  \\\n",
       "0      Bachelor's Degree - Did Not Transfer         0.0         0.0   \n",
       "1                          Associate Degree         0.0         0.0   \n",
       "2      Bachelor's Degree - Did Not Transfer         0.0         0.0   \n",
       "3             Community College Certificate         0.0         0.0   \n",
       "4             Community College Certificate         0.0         0.0   \n",
       "...                                     ...         ...         ...   \n",
       "20700                      Associate Degree         0.0         0.0   \n",
       "20701         Community College Certificate         0.0         0.0   \n",
       "20702  Bachelor's Degree - Did Not Transfer         0.0         0.0   \n",
       "20703  Bachelor's Degree - Did Not Transfer         0.0         0.0   \n",
       "20704                      Associate Degree         0.0         0.0   \n",
       "\n",
       "       WAGE_YEAR3  WAGE_YEAR4  \n",
       "0             0.0         0.0  \n",
       "1             0.0         0.0  \n",
       "2             0.0         0.0  \n",
       "3             0.0         0.0  \n",
       "4             0.0         0.0  \n",
       "...           ...         ...  \n",
       "20700         0.0         0.0  \n",
       "20701         0.0         0.0  \n",
       "20702         0.0         0.0  \n",
       "20703         0.0         0.0  \n",
       "20704         0.0         0.0  \n",
       "\n",
       "[20705 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# set up plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# load the training data\n",
    "data_path = Path('../data/earnings_train.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eff47",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration\n",
    "\n",
    "This notebook explores the earnings dataset to understand data quality, ranges, and relationships between features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7e787",
   "metadata": {},
   "source": [
    "## 1. Data Quality: Data Types and Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types for each column\n",
    "print(\"Data types for each column:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# check for missing data\n",
    "print(\"Missing data analysis:\")\n",
    "print(\"=\" * 60)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_data.index,\n",
    "    'Missing Count': missing_data.values,\n",
    "    'Missing Percentage': missing_percent.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing data found in any column!\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Data types summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Numeric columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"Object/String columns: {len(df.select_dtypes(include=['object']).columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9e6b7",
   "metadata": {},
   "source": [
    "## 2. Range: Unique Values and Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify categorical and numeric columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Categorical columns - unique values:\")\n",
    "print(\"=\" * 60)\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Number of unique values: {unique_count}\")\n",
    "    if unique_count <= 20:\n",
    "        print(f\"  Unique values: {df[col].unique().tolist()}\")\n",
    "    else:\n",
    "        print(f\"  First 20 unique values: {df[col].unique()[:20].tolist()}\")\n",
    "        print(f\"  (Showing first 20 of {unique_count} total)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ranges for numeric columns\n",
    "print(\"\\n\\nNumeric columns - ranges and statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {df[col].min()}\")\n",
    "    print(f\"  Max: {df[col].max()}\")\n",
    "    print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "    print(f\"  Median: {df[col].median():.2f}\")\n",
    "    print(f\"  Std Dev: {df[col].std():.2f}\")\n",
    "    print(f\"  Non-zero values: {(df[col] != 0).sum()} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96028ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if numeric columns are normally distributed using visual inspection\n",
    "# focus on wage columns since those are our target variables\n",
    "wage_cols = [col for col in numeric_cols if 'WAGE' in col]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(wage_cols):\n",
    "    # filter out zeros for better visualization\n",
    "    non_zero_data = df[df[col] > 0][col]\n",
    "    \n",
    "    axes[idx].hist(non_zero_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col} (non-zero values)')\n",
    "    axes[idx].set_xlabel('Wage')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/wage_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# also check with qq plots for normality\n",
    "from scipy import stats\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(wage_cols):\n",
    "    non_zero_data = df[df[col] > 0][col]\n",
    "    stats.probplot(non_zero_data, dist=\"norm\", plot=axes[idx])\n",
    "    axes[idx].set_title(f'Q-Q Plot for {col} (non-zero values)')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/wage_qq_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46699ca3",
   "metadata": {},
   "source": [
    "## 3. Semantics: Column Meanings and Relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e62f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore relationships between columns\n",
    "# check how district code relates to district name\n",
    "print(\"District code and name relationship:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unique district codes: {df['DISTRICT_CODE'].nunique()}\")\n",
    "print(f\"Unique district names: {df['DISTRICT_NAME'].nunique()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "# check if district code is unique per district name\n",
    "district_mapping = df.groupby('DISTRICT_NAME')['DISTRICT_CODE'].nunique()\n",
    "print(f\"\\nDistricts with multiple codes: {(district_mapping > 1).sum()}\")\n",
    "print(f\"Districts with single code: {(district_mapping == 1).sum()}\")\n",
    "\n",
    "# check relationship between demo category and student population\n",
    "print(\"\\n\\nDemographic category and student population relationship:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.groupby('DEMO_CATEGORY')['STUDENT_POPULATION'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad23d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize relationships between wage years\n",
    "# create correlation matrix for wage columns\n",
    "wage_df = df[wage_cols]\n",
    "correlation_matrix = wage_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Between Wage Years')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/wage_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore wage by award category\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(wage_cols):\n",
    "    # filter out zeros and group by award category\n",
    "    non_zero = df[df[col] > 0]\n",
    "    award_wages = non_zero.groupby('AWARD_CATEGORY')[col].mean().sort_values(ascending=False)\n",
    "    \n",
    "    axes[idx].barh(range(len(award_wages)), award_wages.values)\n",
    "    axes[idx].set_yticks(range(len(award_wages)))\n",
    "    axes[idx].set_yticklabels(award_wages.index, fontsize=9)\n",
    "    axes[idx].set_xlabel('Average Wage')\n",
    "    axes[idx].set_title(f'Average {col} by Award Category')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/wage_by_award.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa872e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore wage by demographic category\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(wage_cols):\n",
    "    # filter out zeros and group by demo category and student population\n",
    "    non_zero = df[df[col] > 0]\n",
    "    # focus on race category since it has the most variation\n",
    "    race_data = non_zero[non_zero['DEMO_CATEGORY'] == 'Race']\n",
    "    if len(race_data) > 0:\n",
    "        demo_wages = race_data.groupby('STUDENT_POPULATION')[col].mean().sort_values(ascending=False)\n",
    "        # take top 15 for readability\n",
    "        demo_wages = demo_wages.head(15)\n",
    "        \n",
    "        axes[idx].barh(range(len(demo_wages)), demo_wages.values)\n",
    "        axes[idx].set_yticks(range(len(demo_wages)))\n",
    "        axes[idx].set_yticklabels(demo_wages.index, fontsize=8)\n",
    "        axes[idx].set_xlabel('Average Wage')\n",
    "        axes[idx].set_title(f'Average {col} by Race (top 15)')\n",
    "        axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/wage_by_demographics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3429ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many rows have zero wages vs non-zero wages\n",
    "print(\"Zero vs non-zero wage analysis:\")\n",
    "print(\"=\" * 60)\n",
    "for col in wage_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    non_zero_count = (df[col] > 0).sum()\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Zero values: {zero_count} ({zero_count/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Non-zero values: {non_zero_count} ({non_zero_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# check if rows with zero wages are missing data or actual zeros\n",
    "print(\"\\n\\nRows with all zero wages:\")\n",
    "print(\"=\" * 60)\n",
    "all_zero = (df[wage_cols] == 0).all(axis=1)\n",
    "print(f\"Rows with all wages = 0: {all_zero.sum()} ({all_zero.sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"Rows with at least one non-zero wage: {(~all_zero).sum()} ({(~all_zero).sum()/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d178aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check academic year distribution\n",
    "print(\"\\n\\nAcademic year distribution:\")\n",
    "print(\"=\" * 60)\n",
    "print(df['ACADEMIC_YEAR'].value_counts().sort_index())\n",
    "\n",
    "# check district type distribution\n",
    "print(\"\\n\\nDistrict type distribution:\")\n",
    "print(\"=\" * 60)\n",
    "print(df['DISTRICT_TYPE'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da75643",
   "metadata": {},
   "source": [
    "# Part 2: Build a model to predict WAGE_YEAR4\n",
    "\n",
    "I'll use KNN (K-Nearest Neighbors) to predict WAGE_YEAR4. I'll try different values of k and select the one that performs best on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894eecc7",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b88c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for modeling\n",
    "# we'll use all features except WAGE_YEAR4 (which is our target)\n",
    "# handle missing values in DISTRICT_CODE by filling with 0 (since legislative districts don't have codes)\n",
    "train_df_prep = train_df.copy()\n",
    "train_df_prep['DISTRICT_CODE'] = train_df_prep['DISTRICT_CODE'].fillna(0)\n",
    "\n",
    "# separate features and target\n",
    "X = train_df_prep.drop('WAGE_YEAR4', axis=1)\n",
    "y = train_df_prep['WAGE_YEAR4']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Median: {y.median():.2f}\")\n",
    "print(f\"  Non-zero values: {(y > 0).sum()} ({(y > 0).sum()/len(y)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2620c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "# use label encoding for categorical columns\n",
    "label_encoders = {}\n",
    "X_encoded = X.copy()\n",
    "\n",
    "categorical_cols = ['DISTRICT_TYPE', 'DISTRICT_NAME', 'ACADEMIC_YEAR', 'DEMO_CATEGORY', \n",
    "                     'STUDENT_POPULATION', 'AWARD_CATEGORY']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical columns encoded\")\n",
    "print(f\"Encoded features shape: {X_encoded.shape}\")\n",
    "print(f\"\\nFeature columns: {X_encoded.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9812dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation sets\n",
    "# use 80/20 split to evaluate models\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"\\nTraining target - Non-zero: {(y_train > 0).sum()} ({(y_train > 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Validation target - Non-zero: {(y_val > 0).sum()} ({(y_val > 0).sum()/len(y_val)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b200a",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train k-nearest neighbors model\n",
    "# try different k values and pick the best\n",
    "print(\"Training KNN model...\")\n",
    "k_values = [3, 5, 7, 10, 15]\n",
    "best_k = 5\n",
    "best_knn_rmse = float('inf')\n",
    "best_knn_model = None\n",
    "\n",
    "for k in k_values:\n",
    "    knn_temp = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_temp.fit(X_train, y_train)\n",
    "    knn_temp_pred = knn_temp.predict(X_val)\n",
    "    knn_temp_rmse = np.sqrt(mean_squared_error(y_val, knn_temp_pred))\n",
    "    \n",
    "    if knn_temp_rmse < best_knn_rmse:\n",
    "        best_knn_rmse = knn_temp_rmse\n",
    "        best_k = k\n",
    "        best_knn_model = knn_temp\n",
    "\n",
    "knn_model = best_knn_model\n",
    "knn_pred_train = knn_model.predict(X_train)\n",
    "knn_pred_val = knn_model.predict(X_val)\n",
    "\n",
    "knn_rmse_train = np.sqrt(mean_squared_error(y_train, knn_pred_train))\n",
    "knn_rmse_val = np.sqrt(mean_squared_error(y_val, knn_pred_val))\n",
    "knn_r2_train = r2_score(y_train, knn_pred_train)\n",
    "knn_r2_val = r2_score(y_val, knn_pred_val)\n",
    "\n",
    "print(f\"\\nKNN Results (best k={best_k}):\")\n",
    "print(f\"  Training RMSE: {knn_rmse_train:.2f}\")\n",
    "print(f\"  Validation RMSE: {knn_rmse_val:.2f}\")\n",
    "print(f\"  Training R²: {knn_r2_train:.4f}\")\n",
    "print(f\"  Validation R²: {knn_r2_val:.4f}\")\n",
    "print(f\"\\nTarget RMSE for CS 362:\")\n",
    "print(f\"  Satisfactory: 2500-3000\")\n",
    "print(f\"  Exemplary: < 2500\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d75f96",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_df = pd.read_csv('../data/earnings_test_features.csv')\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"\\nTest data columns: {test_df.columns.tolist()}\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6719d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data the same way as training data\n",
    "test_df_prep = test_df.copy()\n",
    "test_df_prep['DISTRICT_CODE'] = test_df_prep['DISTRICT_CODE'].fillna(0)\n",
    "\n",
    "# encode categorical variables using the same encoders from training\n",
    "X_test = test_df_prep.copy()\n",
    "for col in categorical_cols:\n",
    "    # handle any new categories in test data by using a fallback\n",
    "    le = label_encoders[col]\n",
    "    # get all known classes\n",
    "    known_classes = set(le.classes_)\n",
    "    # map unknown classes to a default value\n",
    "    X_test[col] = X_test[col].astype(str).apply(\n",
    "        lambda x: x if x in known_classes else le.classes_[0]\n",
    "    )\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Test features columns match training: {list(X_test.columns) == list(X_encoded.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on all training data\n",
    "print(f\"\\nTraining final KNN model (k={best_k}) on all training data...\")\n",
    "final_model = KNeighborsRegressor(n_neighbors=best_k)\n",
    "final_model.fit(X_encoded, y)\n",
    "\n",
    "# make predictions on test data\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# ensure no negative predictions (wages can't be negative)\n",
    "test_predictions = np.maximum(test_predictions, 0)\n",
    "\n",
    "print(f\"\\nPredictions made: {len(test_predictions)}\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Min: {test_predictions.min():.2f}\")\n",
    "print(f\"  Max: {test_predictions.max():.2f}\")\n",
    "print(f\"  Mean: {test_predictions.mean():.2f}\")\n",
    "print(f\"  Median: {np.median(test_predictions):.2f}\")\n",
    "print(f\"  Non-zero: {(test_predictions > 0).sum()} ({(test_predictions > 0).sum()/len(test_predictions)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to csv file\n",
    "predictions_df = pd.DataFrame({'WAGE_YEAR4': test_predictions})\n",
    "predictions_df.to_csv('../preds.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to preds.csv\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(predictions_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ed7d3",
   "metadata": {},
   "source": [
    "# Part 3: Reflection\n",
    "\n",
    "## Which features best predict the target outcome (WAGE_YEAR4)?\n",
    "\n",
    "The features that best predict WAGE_YEAR4 are:\n",
    "\n",
    "1. WAGE_YEAR1, WAGE_YEAR2, WAGE_YEAR3 - These are the strongest predictors since they show the wage progression over time. Students who earn more in earlier years tend to earn more in year 4.\n",
    "\n",
    "2. AWARD_CATEGORY - The type of degree or certificate makes a big difference. Bachelor's degrees lead to higher wages than Associate degrees, which lead to higher wages than Community College Certificates.\n",
    "\n",
    "3. DEMO_CATEGORY and STUDENT_POPULATION - These demographic features help capture differences in earnings across different groups.\n",
    "\n",
    "4. DISTRICT_CODE and DISTRICT_NAME - These capture geographic and institutional differences that can affect post-graduation earnings.\n",
    "\n",
    "The model shows that historical wage data (years 1-3) is the most predictive, which makes sense since wage progression tends to be consistent over time.\n",
    "\n",
    "## What does your model say about the people or populations whose data is provided?\n",
    "\n",
    "The model shows a few patterns:\n",
    "\n",
    "1. Wage progression is consistent - students who start with higher wages in year 1 tend to keep that advantage through year 4. Early career earnings are a strong indicator of future earnings.\n",
    "\n",
    "2. Education level matters - Bachelor's degree holders earn significantly more than those with Associate degrees or certificates. This matches typical labor market patterns where higher education correlates with higher earnings.\n",
    "\n",
    "3. There's significant variation across demographic groups and districts. Factors beyond individual achievement, like geographic location, institutional resources, and systemic factors, play a role in post-graduation earnings.\n",
    "\n",
    "4. Most rows (about 85%) have zero wages. This likely means there weren't enough students in that specific demographic/district/award combination to report meaningful wage data, so the values were set to zero for privacy or statistical reasons. This shows the challenge of working with aggregated data where privacy concerns limit what can be reported.\n",
    "\n",
    "## What features, if any, would you like to have had to make a better model?\n",
    "\n",
    "To improve the model, I would want:\n",
    "\n",
    "1. Individual-level data instead of aggregated data - This would let me model individual factors better instead of just group averages.\n",
    "\n",
    "2. More detailed education information - Field of study, GPA, specific courses taken, and whether students completed internships or had work experience during school.\n",
    "\n",
    "3. Geographic and economic context - Cost of living in the area, local job market conditions, unemployment rates, and industry presence in the region.\n",
    "\n",
    "4. Student background information - Family income, first-generation college student status, and high school performance metrics.\n",
    "\n",
    "5. Job market information - Industry of employment, job title, full-time vs part-time status, and whether the job is related to their field of study.\n",
    "\n",
    "6. Time series data - Having data from multiple academic years would help understand trends and make the model work better on new data.\n",
    "\n",
    "7. More complete data - Having wage data for more combinations of demographics/districts/awards would reduce the number of zero values and provide more training examples.\n",
    "\n",
    "These additional features would probably help the model predict better and give clearer answers about what actually affects post-graduation earnings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
